{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd \r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from imutils import paths\r\n",
    "import seaborn as sns\r\n",
    "import random\r\n",
    "import time\r\n",
    "from datetime import datetime"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import cv2\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import confusion_matrix"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import os\r\n",
    "from skillsnetwork import cvstudio"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Initialize the CV Studio Client\r\n",
    "cvstudioClient = cvstudio.CVStudio\r\n",
    "\r\n",
    "# Download All Images\r\n",
    "cvstudioClient.downloadAll"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<function skillsnetwork.cvstudio.CVStudio.downloadAll(self)>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "annotations = cvstudioClient.get_annotations"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's view the format of the annotations we've just downloaded. The following code will display only the first 5 annotations. The annotations will come in a JSON file. What you can see is the image name as the key and dog as label object."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "first_five = {k: annotations[\"annotations\"][k] for k in list(annotations[\"annotations\"])[:5]}\r\n",
    "first_five"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load and Plot and Image\r\n",
    "We will train and classify your images using the k-NN classifier using the OpenCV library. Before we start, let's get the images and take a look at some of them.\r\n",
    "\r\n",
    "We will pick random images and take a look:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "random_filename = 'images/' + random.choice(list(annotations[\"annotations\"].keys()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot, read and show a random image using the cv2.imread and the matplotlib library.\r\n",
    "\r\n",
    "We will also change the color space to RGB so we can plot it since OpenCV reads images as BGR. Early developers at OpenCV chose BGR color format because it was the format that was popular among camera manufacturers and software providers."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "sample_image = cv2.imread(random_filename)\r\n",
    "## Convert to RGB\r\n",
    "image = cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB)\r\n",
    "## Now plot the image\r\n",
    "plt.figure(figsize=(10,10))\r\n",
    "plt.imshow(image, cmap = \"gray\")\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To perform KNN on the dataset, we will need to process the data. I will use the sample image to explain each line of code.\r\n",
    "\r\n",
    "Convert image to grayscale - grayscale simplifies the algorithm and reduces computational requirements."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sample_image = cv2.cvtColor(sample_image,cv2.COLOR_BGR2GRAY)\r\n",
    "plt.figure(figsize=(10,10))\r\n",
    "plt.imshow(sample_image, cmap = \"gray\")\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Resize image - resizing image helps the algorithm train faster."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "sample_image = cv2.resize(sample_image, (32, 32))\r\n",
    "plt.imshow(sample_image, cmap = \"gray\")\r\n",
    "plt.show()\""
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "hry\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Flatten image - makes the image a numpy array for the algorithm to handle and recognize."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pixels = sample_image.flatten()\r\n",
    "pixels"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Repeat the Process Above for All Images\r\n",
    "We will now repeat the same process above to load and process all the images youâ€™ve annotated and label each picture. KNN is supervised machine learning algorithm, therefore we have to explicitly create labels for the machine.\r\n",
    "\r\n",
    "Depending on how much data you have, this will take a while to run..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "image_paths=list(paths.list_images('images'))\r\n",
    "train_images=[]\r\n",
    "train_labels=[]\r\n",
    "class_object=annotations['labels']\r\n",
    "\r\n",
    "for (i,image_path in) enumerate(image_paths):\r\n",
    "    # read the image\r\n",
    "    image=cv2.imread(image_path)\r\n",
    "    # make image gray\r\n",
    "    image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\r\n",
    "    # label image using annotations\r\n",
    "    label=class_object.index(annotations['annotation'][image_path[7:0]][0]['label'])\r\n",
    "    tmp_label = annotations[\"annotations\"][image_path[7:]][0]['label']\r\n",
    "    # resize image\r\n",
    "    image=cv2.resize(image,(32,32))\r\n",
    "    #flatten the image\r\n",
    "    pixels=image.flatten()\r\n",
    "    #append flattened image\r\n",
    "    train_images.append(pixels)\r\n",
    "    train_labels.append(label)\r\n",
    "    print('loaded.. image',str(i+1),\" is a cat\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create an array of the train_images and train_labels. OpenCV only identifies arrays of type float32 for the training samples and array of shape (label size, 1) for the training labels. We can do that by specifying astype('float32') on the numpy array of the training samples and convert the training labels to integers and reshape the array to (label size, 1). When you print the train_labels, the array will look like this [[1], [0], ..., [0]]"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_images=np.array(train_images).astype(np.float32)\r\n",
    "train_labels=np.array(train_labels).astype(int)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_labels=train_labels.reshape((train_labels.size,1))\r\n",
    "train_labels"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_size=0.2\r\n",
    "train_samples,test_samples,train_labels,test_labels=train_test_split(train_images,train_labels,test_size,random_state=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To train the KNN model, we will use the cv2.ml.KNearest_create() from the OpenCV library. We need to define how many nearest neighbors will be used for classification as a hyper-parameter k. This parameter k can be toggled with/tuned in the training or model validation process. Fit the training and test images and get the accuracy score of the model.\r\n",
    "\r\n",
    "We will try multiple values of k to find the optimal value for the dataset we have. k refers to the number of nearest neighbours to include in the majority of the voting process.\r\n",
    "\r\n",
    "Note: Depending on how large your dataset is, it may take a few seconds to run."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "start_datatime=datetime.now()\r\n",
    "knn=cv2.ml.KNearest_create()\r\n",
    "knn.train(train_samples,cv2.ml.ROW_SAMPLE,train_labels)\r\n",
    "\r\n",
    "#get different values of k\r\n",
    "k_values=[1,2,3,4,5]\r\n",
    "K_result=[]\r\n",
    "\r\n",
    "for k in k_values:\r\n",
    "    ret,result,neighbors,distance=knn.findNearest(test,samples,k=k)\r\n",
    "    k_result.append(result)\r\n",
    "\r\n",
    "flattened=[]\r\n",
    "for res in k_result:\r\n",
    "    flat_result = [item for sublist in res for item in sublist]\r\n",
    "    flattened.append(flat_result)\r\n",
    "\r\n",
    "end_datetime = datetime.now()\r\n",
    "print('Training Duration: ' + str(end_datetime-start_datetime))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will get the accuracy value for each value of k i.e., how many percent of the images were classified correctly? We will create a confusion matrix for a more comprehensive classification model evaluation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# create a list to save accuracy and confusion matrix\r\n",
    "accuracy_res=[]\r\n",
    "con_matrix=[]\r\n",
    "for k in k_result:\r\n",
    "    label_names=[0,1]\r\n",
    "    cmx=confusion_matrix[test_labels,k_res,labels=label_names]\r\n",
    "    con_matrix.append(cmx)\r\n",
    "    # get values for when we predict accurately\r\n",
    "    matches=k_res==test_labels\r\n",
    "    correct=np.count_nonzero(matches)\r\n",
    "    #calculate accuracy\r\n",
    "    accuracy=correct*100/result.size\r\n",
    "    accuracy_res.append(accuracy)\r\n",
    "\r\n",
    "# store accuracy for later when we create the graph\r\n",
    "res_accuracy={k_values[i]:accuracy_res[i] for i range(len(k_values))}\r\n",
    "list_res=sorted(res_accuracy.items())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "t=0\r\n",
    "for array in con_matrix:\r\n",
    "    df_cm=pd.DataFrame(array)\r\n",
    "    sns.set(font_scale=1.4)\r\n",
    "    sns.heatmap(df_cm,annot=True,annot_kws={'size':16},fmt='.0f')\r\n",
    "    t+=1\r\n",
    "    title=\"Confusion matrix for k=: \",str(t)\r\n",
    "    plt.title(title)\r\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will plot the accuracy to see which one is highest i.e., what percentage of images were classified correctly?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# plot accuracy against\r\n",
    "x,y=zip(*list_res)\r\n",
    "plt.plot(x,y)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "k_best=max(list_res,key=lambda,item=item[1])[0]\r\n",
    "k_best"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "let's report the result back to cv studio"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "parameters = {\r\n",
    "    'k_best': k_best\r\n",
    "}\r\n",
    "result = cvstudioClient.report(started=start_datetime, completed=end_datetime, parameters=parameters, accuracy=list_res)\r\n",
    "\r\n",
    "if result.ok:\r\n",
    "    print('Congratulations your results have been reported back to CV Studio!')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Congratulations your results have been reported back to CV Studio!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# save the knn model to a file\r\n",
    "knn.save('knn_samples.yml')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit"
  },
  "interpreter": {
   "hash": "0e091db8d58018cc79bd95d4c344ae6fb50dc1dda4747c0206fad4c7e07cd6fa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}